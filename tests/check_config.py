#!/usr/bin/env python3
"""
é…ç½®æ£€æŸ¥è„šæœ¬
ç”¨äºéªŒè¯ç¯å¢ƒé…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½.envæ–‡ä»¶
load_dotenv(project_root / ".env")

def check_env_file():
    """æ£€æŸ¥.envæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    env_file = project_root / ".env"
    if env_file.exists():
        print("âœ… .envæ–‡ä»¶å­˜åœ¨")
        return True
    else:
        print("âŒ .envæ–‡ä»¶ä¸å­˜åœ¨")
        print("è¯·æŒ‰ç…§ CONFIG_SETUP.md ä¸­çš„è¯´æ˜åˆ›å»º .env æ–‡ä»¶")
        return False

def check_required_vars():
    """æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡"""
    print("\nğŸ” æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    
    # æ£€æŸ¥LLMæä¾›å•†
    provider = os.getenv('LLM_PROVIDER', 'modelscope')
    print(f"LLMæä¾›å•†: {provider}")
    
    if provider == "modelscope":
        # æ£€æŸ¥é­”æ­é…ç½®
        api_key = os.getenv('MODELSCOPE_API_KEY', '')
        api_base = os.getenv('MODELSCOPE_API_BASE', '')
        model = os.getenv('MODELSCOPE_MODEL', '')
        
        print(f"é­”æ­APIå¯†é’¥: {'âœ… å·²è®¾ç½®' if api_key and api_key != 'your_modelscope_api_key_here' else 'âŒ æœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼'}")
        print(f"é­”æ­APIåŸºç¡€URL: {api_base}")
        print(f"é­”æ­æ¨¡å‹: {model}")
        
        if not api_key or api_key == 'your_modelscope_api_key_here':
            print("âš ï¸  è¯·è®¾ç½®ä½ çš„é­”æ­è®¿é—®ä»¤ç‰Œ")
            return False
        return True
        
    elif provider == "openai":
        # æ£€æŸ¥OpenAIé…ç½®
        api_key = os.getenv('OPENAI_API_KEY', '')
        api_base = os.getenv('OPENAI_API_BASE', '')
        model = os.getenv('OPENAI_MODEL', '')
        
        print(f"OpenAI APIå¯†é’¥: {'âœ… å·²è®¾ç½®' if api_key and api_key != 'your_openai_api_key_here' else 'âŒ æœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼'}")
        print(f"OpenAI APIåŸºç¡€URL: {api_base}")
        print(f"OpenAIæ¨¡å‹: {model}")
        
        if not api_key or api_key == 'your_openai_api_key_here':
            print("âš ï¸  è¯·è®¾ç½®ä½ çš„OpenAI APIå¯†é’¥")
            return False
        return True
    
    else:
        print(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        return False

def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥"""
    print("\nğŸ”— æµ‹è¯•LLMè¿æ¥...")
    
    try:
        from backend.app.services.llm_gateway import llm_gateway
        
        # æ£€æŸ¥é…ç½®
        if not llm_gateway.api_key:
            print("âŒ LLM APIå¯†é’¥æœªé…ç½®")
            return False
        
        # æµ‹è¯•è¿æ¥
        is_valid = llm_gateway.validate_connection()
        if is_valid:
            print("âœ… LLMè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        else:
            print("âŒ LLMè¿æ¥æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ LLMè¿æ¥æµ‹è¯•å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ é…ç½®æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥.envæ–‡ä»¶
    env_ok = check_env_file()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    vars_ok = check_required_vars()
    
    # æµ‹è¯•LLMè¿æ¥
    connection_ok = test_llm_connection()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æ£€æŸ¥æ€»ç»“:")
    print(f"  .envæ–‡ä»¶: {'âœ…' if env_ok else 'âŒ'}")
    print(f"  ç¯å¢ƒå˜é‡: {'âœ…' if vars_ok else 'âŒ'}")
    print(f"  LLMè¿æ¥: {'âœ…' if connection_ok else 'âŒ'}")
    
    if env_ok and vars_ok and connection_ok:
        print("\nğŸ‰ é…ç½®æ£€æŸ¥é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
        return True
    else:
        print("\nâš ï¸  é…ç½®æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å‚è€ƒ CONFIG_SETUP.md è¿›è¡Œé…ç½®ã€‚")
        return False

if __name__ == "__main__":
    main() 